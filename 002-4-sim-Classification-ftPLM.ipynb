{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623af36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import os \n",
    "import pandas as pd \n",
    "import re \n",
    "import pickle \n",
    "from tqdm import tqdm \n",
    "from sentence_transformers import util\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm \n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import time\n",
    "\n",
    "# device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"0\" \n",
    "\n",
    "with open('sbert_sts_training.pickle', 'rb') as pkl:\n",
    "    defect_sbert = pickle.load(pkl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960e7c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "mode = 'target classification system'\n",
    "filename='datset file'\n",
    "readfile = pd.read_csv ('./data/fs_data/'+filename, encoding='utf-8')\n",
    "readfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d39866d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = set(readfile['label'].to_list())\n",
    "len(list(label))\n",
    "\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ad980",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nv_label_df= pd.read_excel('anchor words list.xlsx', sheet_name=mode) \n",
    "nv_dict= nv_label_df.to_dict()\n",
    "criteria_name = list(nv_dict.keys())\n",
    "print(criteria_name)\n",
    "\n",
    "criteria_keywords=[]\n",
    "for k in nv_dict.values():\n",
    "    temp =[ word for word in list(k.values()) if type(word) is not float]\n",
    "    criteria_keywords.append(temp)\n",
    "print(\"criteria_keywords: \",criteria_keywords)\n",
    "\n",
    "nv_anchor_words=[]\n",
    "for k, v in zip(criteria_name, criteria_keywords): \n",
    "    v.append(k)\n",
    "    nv_anchor_words.append(' '.join(v))\n",
    "    \n",
    "print(nv_anchor_words)\n",
    "len(nv_anchor_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ed97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute embeddings of defect complaint data \n",
    "\n",
    "complaints = readfile['complaint']\n",
    "complaint_emb = defect_sbert.encode(complaints, convert_to_tensor=True, show_progress_bar = True)\n",
    "print(complaint_emb.size())\n",
    "\n",
    "criteria_name_emb = defect_sbert.encode(nv_anchor_words, convert_to_tensor=True, show_progress_bar = True)   #input_className\n",
    "print(criteria_name_emb.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6975a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from sentence_transformers import util\n",
    "\n",
    "#Compute cosine-similarities for each sentence with each other sentence\n",
    "cosine_scores = util.cos_sim(complaint_emb, criteria_name_emb)\n",
    "print(cosine_scores.size())\n",
    "\n",
    "#Find the pairs with the highest cosine similarity scores\n",
    "max_cos = []\n",
    "for i in tqdm(range(len(cosine_scores))):\n",
    "    temp =[]\n",
    "    for j in range(len(criteria_name_emb)):\n",
    "        temp.append(cosine_scores[i][j])\n",
    "    max_cos.append(temp.index(max(temp)))\n",
    "\n",
    "print(len(max_cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e596197c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class encoding \n",
    "ct_idx_dict = {(i):criteria_name[i] for i in range(0, len(criteria_name))}\n",
    "print(ct_idx_dict)\n",
    "\n",
    "map_to_criteria=[]\n",
    "for i in max_cos: \n",
    "    for k, v in ct_idx_dict.items():\n",
    "        if i == k:\n",
    "            map_to_criteria.append(''.join(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb0002",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "resultDF = readfile[['complaint', 'label']]\n",
    "resultDF['pred_label']= map_to_criteria\n",
    "resultDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261030b3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_pred = resultDF['pred_label'].to_list()\n",
    "y_ans = resultDF['label'].to_list()\n",
    "\n",
    "print(classification_report(y_ans, y_pred))\n",
    "print(precision_recall_fscore_support(y_ans, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7483bf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria_name_A =['Cabinet', \n",
    "                    'Gas and fire system', \n",
    "                    'Condensation',\n",
    "                    'Structural defect',\n",
    "                    'Heating system',\n",
    "                    'Leakage',\n",
    "                    'Paperwork',\n",
    "                    'Woodframe work',\n",
    "                    'Masonry',\n",
    "                    'Flooring',\n",
    "                    'Stonework',\n",
    "                    'Finish of sink',\n",
    "                    'Airconditioning system',\n",
    "                    'Appliance',\n",
    "                    'Sanitary and plumbing',\n",
    "                    'Electrical system',\n",
    "                    'Doors and windows',\n",
    "                    'Tiling',\n",
    "                    'Communication system']\n",
    "\n",
    "criteria_name_B=['Opening', 'Condensation', 'Stability', 'Leakage', 'Step', 'Detachement', 'Poor surface', 'Uninstallation', \n",
    "                  'Corrosion', 'Misalignment', 'Contamination', 'Disconnection', 'Out of orders', 'On/Off defect', 'Poor joint', \n",
    "                  'Scratch', 'Caulking defect', 'Crack', 'Broken']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f1a17",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns # used for plot interactive graph.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "\n",
    "conf_mat = confusion_matrix(y_ans, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(conf_mat, annot=True, cmap=\"Blues\", fmt='d',\n",
    "            xticklabels=criteria_name_A, \n",
    "            yticklabels=criteria_name_A)\n",
    "plt.ylabel('Actual', size=12)\n",
    "plt.xlabel('Predicted', size=12)\n",
    "plt.title(\"Confusion Matrix \", size=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b6e60",
   "metadata": {},
   "source": [
    "## Fine-tuned Word2Vec Similarity \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5938c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import gensim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as ss\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "from scipy import spatial\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models import Word2Vec\n",
    "%matplotlib inline\n",
    "\n",
    "kow2v_model= 'ko_w2v_defect-0710-v2.bin' \n",
    "#feature vec = 200\n",
    "kovec = Word2Vec.load('./ko-w2v/'+kow2v_model)\n",
    "\n",
    "\n",
    "def getSentenceMeanEmbeddings (sentenceCorpus):\n",
    "    sent_embdding_list =[]\n",
    "    for line in sentenceCorpus:\n",
    "        sen2vec = None\n",
    "        count=0\n",
    "        for word in line:\n",
    "#             print(word)\n",
    "            if word in kovec.wv.index_to_key:\n",
    "                count +=1\n",
    "                if sen2vec is None:\n",
    "                    sen2vec = kovec.wv.get_vector(word)\n",
    "                else: \n",
    "                    sen2vec = sen2vec+ kovec.wv.get_vector(word)\n",
    "        if sen2vec is not None:\n",
    "            sen2vec = sen2vec/count\n",
    "            sent_embdding_list.append(sen2vec)\n",
    "            \n",
    "    return sent_embdding_list\n",
    "\n",
    "\n",
    "\n",
    "# Fine-tuned_ Word2Vec model \n",
    "complaints = readfile['complaint']\n",
    "\n",
    "complaint_emb_w2v = getSentenceMeanEmbeddings (complaints)\n",
    "criteria_name_emb_w2v = getSentenceMeanEmbeddings(nv_anchor_words) # input_className ( MI 키워드 집합일때)\n",
    "\n",
    "print(len(complaint_emb_w2v), len(criteria_name_emb_w2v))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7008e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "from sentence_transformers import util\n",
    "\n",
    "#Compute cosine-similarities for each sentence with each other sentence\n",
    "cosine_scores = util.cos_sim(complaint_emb_w2v, criteria_name_emb_w2v)\n",
    "print(cosine_scores.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca3d042",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the pairs with the highest cosine similarity scores\n",
    "max_cos = []\n",
    "for i in tqdm(range(len(cosine_scores))):\n",
    "    temp =[]\n",
    "    for j in range(len(criteria_name_emb_w2v)):\n",
    "        temp.append(cosine_scores[i][j])\n",
    "#     print(temp)\n",
    "    max_cos.append(temp.index(max(temp)))\n",
    "#     print(temp.index(max(temp)))\n",
    "#     break\n",
    "print(len(max_cos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6fd557",
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_idx_dict = {(i):criteria_name[i] for i in range(0, len(criteria_name))}\n",
    "print(ct_idx_dict)\n",
    "\n",
    "map_to_criteria=[]\n",
    "for i in max_cos: \n",
    "    for k, v in ct_idx_dict.items():\n",
    "        if i == k:\n",
    "            map_to_criteria.append(''.join(v))\n",
    "            \n",
    "            \n",
    "resultDF_w2v = readfile[['complaint', 'label']]\n",
    "resultDF_w2v['pred_label']= map_to_criteria\n",
    "resultDF_w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d7360e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "y_pred = resultDF_w2v['pred_label'].to_list()\n",
    "y_ans = resultDF_w2v['label'].to_list()\n",
    "\n",
    "print(classification_report(y_ans, y_pred))\n",
    "print(precision_recall_fscore_support(y_ans, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd32c07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727484d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
