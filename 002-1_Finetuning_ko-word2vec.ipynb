{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd176077",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Korean Word2Vec finetuning\n",
    "import gensim\n",
    "import numpy as np\n",
    "ko_wv_model = gensim.models.Word2Vec.load(\"./ko-w2v/ko.bin\")\n",
    "print(ko_wv_model.wv.vector_size)\n",
    "print(ko_wv_model.corpus_count)\n",
    "print(len(ko_wv_model.wv.vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355388ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = ko_wv_model.wv.vocab\n",
    "idx_to_count = np.asarray([vocab.count for vocab in sorted(vocabs.values(), key=lambda x:x.index)])\n",
    "vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0026deca",
   "metadata": {},
   "outputs": [],
   "source": [
    "word=\"도배\"\n",
    "try:\n",
    "    ko_wv_model.wv.most_similar(word)\n",
    "except:\n",
    "    print(\"{}: 없음\".format(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af411ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import scipy.sparse as ss\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#Preprocessing \n",
    "import MeCab\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import font_manager, rc\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist \n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "\n",
    "from konlpy.tag import Mecab \n",
    "from konlpy.tag import *\n",
    "\n",
    "mc = Mecab(dicpath='C:\\mecab\\mecab-ko-dic') # The path of the MeCab-ko dictionary.\n",
    "m = MeCab.Tagger(\"-O wakati\")\n",
    "\n",
    "class MyTokenizer:\n",
    "    def __init__(self, tagger):\n",
    "        self.tagger = tagger\n",
    "    \n",
    "    def __call__(self, sent):\n",
    "        postags=['NNP', 'NNG', 'VV', 'VA','SL']\n",
    "        pos = self.tagger.pos(sent)\n",
    "        pos = [word for (word, pos) in mc.pos(sent, flatten=True) if pos in postags and len(word)>1]\n",
    "        return pos\n",
    "\n",
    "my_tokenizer = MyTokenizer(Mecab(dicpath='C:\\mecab\\mecab-ko-dic'))\n",
    "\n",
    "# Defect Data load \n",
    "dldefect_df = pd.read_excel('defect dataset file ')\n",
    "rawComplaints = dldefect_df.apply(lambda row: \" \".join(re.sub(\"[^a-zA-Z가-힣]+\",\" \", row.complaint).split()), 1).to_list()\n",
    "print(len(rawComplaints))\n",
    "dldefect_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7f9de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawComplaints = list(set(rawComplaints))\n",
    "print(\"Remove duplicates: \",len(rawComplaints))\n",
    "\n",
    "tokenized_text = [my_tokenizer(line) for line in rawComplaints]\n",
    "print(len(tokenized_text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2460ff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "#1) LOAD pre-trained key vector\n",
    "ko_model_keyVector = KeyedVectors.load_word2vec_format(\"./ko-w2v/ko.bin.gz\", binary =False)\n",
    "model_2 = Word2Vec(size=ko_model_keyVector.vector_size, min_count=1, sg=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3627ccb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) Build a new model's vocabualry first\n",
    "a = model_2.build_vocab(tokenized_text)\n",
    "total_examples = model_2.corpus_count\n",
    "print(total_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a3a672",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_2.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b1be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(ko_model_keyVector.wv.vocab.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc29556",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4) BUILD vocab by PreTrainedKeyvector word Vocabulary\n",
    "# model_2.build_vocab([[]]) # list of list \n",
    "model_2.build_vocab([list(ko_model_keyVector.wv.vocab.keys())], update=True)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c827c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) INITIALIZED word vector \n",
    "model_2.intersect_word2vec_format(\"./ko-w2v/ko.bin.gz\", binary=False, lockf=1.0,  encoding='ISO-8859-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e0e2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model_2.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf443fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6) Train new dataset \n",
    "print(model_2.wv['도배'][:5])\n",
    "model_2.train(tokenized_text, total_examples=total_examples, epochs=model_2.iter)\n",
    "print(model_2.wv['도배'][:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b559c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.most_similar(\"도배\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aac3f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.most_similar(\"미장\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73030e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_2.wv.vector_size)\n",
    "print(model_2.corpus_count)\n",
    "print(len(model_2.wv.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56d8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(model_2.wv.vocab))\n",
    "\n",
    "vocabs = model_2.wv.vocab\n",
    "idx_to_count = np.asarray([vocab.count for vocab in sorted(vocabs.values(), key=lambda x:x.index)])\n",
    "idx_to_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12883b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "addedWordNum =0\n",
    "for k in model_2.wv.vocab:\n",
    "    result = ko_wv_model.wv.vocab.get(k, \"0\")\n",
    "    if result==\"0\":\n",
    "        addedWordNum+=1\n",
    "        print(k, end=\",\")\n",
    "print(\"number of added words:\", addedWordNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a69e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save fine-tuned word2vec mode\n",
    "model_2.save(\"./ko-w2v/ko_w2v_defect-0710-v2.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1238e0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "nlpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
